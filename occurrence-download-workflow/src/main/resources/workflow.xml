<?xml version="1.0" encoding="utf-8"?>
<!-- ~ Copyright 2012 Global Biodiversity Information Facility (GBIF) ~ ~
  Licensed under the Apache License, Version 2.0 (the "License"); ~ you may
  not use this file except in compliance with the License. ~ You may obtain
  a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 ~
  ~ Unless required by applicable law or agreed to in writing, software ~ distributed
  under the License is distributed on an "AS IS" BASIS, ~ WITHOUT WARRANTIES
  OR CONDITIONS OF ANY KIND, either express or implied. ~ See the License for
  the specific language governing permissions and ~ limitations under the License. -->
<workflow-app name="${occurrence.environment}-occurrence-download" xmlns="uri:oozie:workflow:0.2">

  <start to="occurrence_count" />
  
  <action name="occurrence_count">
    <java>
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <main-class>org.gbif.occurrence.download.oozie.OccurrenceCount</main-class>
      <arg>${solr_query}</arg>
      <arg>${wf:id()}</arg>
      <capture-output/>
    </java>

    <ok to="make_query_decision" />
    <error to="kill" />
  </action> 
  
   <decision name="make_query_decision">
    <switch>
      <!-- it's a small download -->
      <case to="small_download">
        ${wf:actionData('occurrence_count')['is_small_download']}
      </case>    
      <default to="big_download" />
    </switch>
  </decision>
  
  <fork name="big_download">
    <path start="query_interpreted" />
    <path start="query_verbatim" />
  </fork>

  <action name="small_download">
    <java>
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <main-class>org.gbif.occurrence.download.file.DownloadTableBuilder</main-class>
      <arg>${query_result_table}_interpreted</arg>
      <arg>${query_result_table}_verbatim</arg>
      <arg>${query_result_table}_multimedia</arg>
      <arg>${citation_table}</arg>
      <arg>${solr_query}</arg>
      <arg>${hdfs.namenode}</arg>
      <arg>${hdfs_hive_path}</arg>
      <arg>${wf:id()}</arg>
    </java>

    <ok to="copy_and_zip" />
    <error to="failure_clean_hdfs_dirs" />
  </action>
  
  <action name="query_interpreted">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/create_occurrence_table.q</script>

      <param>occurrence_record=${occurrence.env_prefix}.occurrence_hdfs</param>
      <param>select=${select_interpreted}</param>
      <param>query=${query}</param>
      <param>query_result_table=${occurrence.env_prefix}.${query_result_table}_interpreted</param>
    </hive>

    <ok to="secondary_files" />
    <error to="failure_queries" />
  </action>

  <action name="query_verbatim">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/create_occurrence_table.q</script>

      <param>occurrence_record=${occurrence.env_prefix}.occurrence_hdfs</param>
      <param>select=${select_verbatim}</param>
      <param>query=${query}</param>
      <param>query_result_table=${occurrence.env_prefix}.${query_result_table}_verbatim</param>
    </hive>

    <ok to="bundling" />
    <error to="failure_queries" />
  </action>

  <fork name="secondary_files">
    <path start="citation" />
    <path start="multimedia" />
  </fork>
  
  <action name="multimedia">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/create_multimedia_table.q</script>

      <param>result_multimedia_table=${occurrence.env_prefix}.${query_result_table}_multimedia</param>            
      <param>occurrence_intepreted_table=${occurrence.env_prefix}.${query_result_table}_interpreted</param>
      <param>occurrence_record=${occurrence.env_prefix}.occurrence_hdfs</param>
    </hive>

    <ok to="bundling" />
    <error to="failure_queries" />
  </action>
  
  <action name="citation">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/citation.q</script>

      <param>query_result_table=${occurrence.env_prefix}.${query_result_table}_interpreted</param>
      <param>citation_table=${occurrence.env_prefix}.${citation_table}</param>
    </hive>

    <ok to="bundling" />
    <error to="failure_queries" />
  </action>

  <join name="bundling" to="copy_and_zip"/>
  
  <join name="failure_queries" to="failure_drop_table"/>

  <action name="copy_and_zip">
    <java>
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <configuration>
        <property>
          <name>mapred.queue.name</name>
          <value>default</value>
        </property>
      </configuration>

      <main-class>org.gbif.occurrence.download.oozie.ArchiveBuilder</main-class>
      <arg>${hdfs.namenode}</arg>
      <arg>${hdfs_hive_path}</arg>
      <arg>${query_result_table}_interpreted</arg>
      <arg>${query_result_table}_verbatim</arg>
      <arg>${query_result_table}_multimedia</arg>
      <arg>${citation_table}</arg>
      <arg>/mnt/auto/${occurrence.environment}/occurrence-download</arg>
      <arg>${wf:id()}</arg>
      <arg>${gbif_user}</arg>
      <arg>${gbif_filter}</arg>
      <arg>${download_link}</arg>
      <arg>${registry.ws.url}</arg>
      <arg>${wf:actionData('occurrence_count')['is_small_download']}</arg>
    </java>

    <ok to="cleaning_decision" />
    <error to="failure_cleaning_decision" />
  </action>

  <decision name="cleaning_decision">
    <switch>
      <!-- it's a small download the delete the occurrence data and citations file -->
      <case to="clean_hdfs_dirs">
       ${wf:actionData('occurrence_count')['is_small_download']}
      </case>
      <default to="drop_table" />
    </switch>
  </decision>

  <decision name="failure_cleaning_decision">
    <switch>
      <!-- it's a small download the delete the occurrence data and citations file -->
      <case to="failure_clean_hdfs_dirs">
        ${wf:actionData('occurrence_count')['is_small_download']}
      </case>
      <default to="failure_drop_table" />
    </switch>
  </decision>

  <action name="drop_table">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/drop_table.q</script>

      <param>query_result_table=${occurrence.env_prefix}.${query_result_table}</param>
      <param>citation_table=${occurrence.env_prefix}.${citation_table}</param>
    </hive>

    <ok to="end" />
    <error to="kill" />
  </action>


  <action name="failure_drop_table">
    <hive xmlns="uri:oozie:hive-action:0.2">
      <job-tracker>${hadoop.jobtracker}</job-tracker>
      <name-node>${hdfs.namenode}</name-node>
      <job-xml>conf/hive-default.xml</job-xml>
      <script>hive-scripts/drop_table.q</script>

      <param>query_result_table=${occurrence.env_prefix}.${query_result_table}</param>
      <param>citation_table=${occurrence.env_prefix}.${citation_table}</param>
    </hive>

    <ok to="kill" />
    <error to="kill" />
  </action>

  <action name="clean_hdfs_dirs">
    <fs>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${query_result_table}_interpreted'/>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${query_result_table}_verbatim'/>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${query_result_table}_multimedia'/>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${citation_table}'/>
    </fs>
    <ok to="end" />
    <error to="kill" />
  </action>

  <action name="failure_clean_hdfs_dirs">
    <fs>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${query_result_table}_interpreted'/>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${query_result_table}_verbatim'/>
      <delete path='${hdfs.namenode}${occurrence.download.hive.hdfs.out}/${citation_table}'/>
    </fs>
    <ok to="kill" />
    <error to="kill" />
  </action>

  <kill name="kill">
    <message>Occurrence download failed:[${wf:errorMessage(wf:lastErrorNode())}]</message>
  </kill>

  <end name="end" />

</workflow-app>
