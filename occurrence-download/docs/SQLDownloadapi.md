# SQL Download API (Beta)
Note: This feature is in beta, and deployed for testing, feedbacks and issues can be reported.

## Table of Contents
1. [Motivation](#motivation)
2. [Introduction](#introduction)
3. [Feature](#feature)
    1. [API Endpoints](#api-endpoints)
    2. [SQL Functions supported](#sql-functions-supported)
    3. [Citation and Licenses for Downloads](#citation-and-licenses-for-downloads)
4. [Getting Started](#getting-started)
5. [Future Works](#future-works)
6. [Open Questions](#open-questions)
7. [Conclusion](#conclusion)

## Motivation
GBIF has been providing gbif data snapshots based on selected criteria for downloads in different format SIMPLE CSV, DWCA and  AVRO. However it has been observed that they are of limited use to various gbif users as they need to re-process these download for analytical relevance or textual brevity. Performing these operations is quite cumbersome on MS Excel at the user end, and when the downloads are big it is very difficult due to lack of access to computation resources and softwares. 

## Introduction
SQL queries are one of the most popular ways to query the data. It enables various functions or transformations to access the fields or data as user desires. SQL Download API will help gbif users to download the gbif occurrence data as a simple plain SQL query.  This feature helps the advanced users to get the relevant data in simple CSV format carrying out textual transformations and analytical processing on gbif infrastructure. 

## Feature
The SQL download is supported by 3 different types of services: 
1. _SQL Describe service_: This service describe all the queryable fields, there types and description. 
2. _SQL Validation service_: Validate the SQL query before executing the query for download. This helps user to create a proper SQL query before performing download on gbif infrastructure. 
3. _SQL Download service_: This service helps to create the SQL download at gbif infrastructure and returns the downloadkey which can be used to see the progress of gbif downloads.  

### API Endpoints

#### SQL Describe
No Authorization needed

##### Request 

```
GET /v1/occurrence/download/request/sql/describe HTTP/1.1
Host: api.gbif.org
cache-control: no-cache
```

##### Response 
```
[
    {
        "columnName": "gbifid",
        "dataType": "int",
        "comment": "unique id for the occurrence, generated by gbif."
    }, ….
]
```

#### SQL Validation

No Authorization needed

##### Sample Request

```
GET /v1/occurrence/download/request/sql/validate?sql=select `decimallatitude`/10 `lat`, `decimallongitude`/10 `lon`, count(`species`) `count` from `occurrence` GROUP BY `decimallatitude`/10, `decimallongitude`/10 HTTP/1.1
Host: api.gbif.org
Content-Type: application/json
cache-control: no-cache 
```

##### Sample Response
```
{
    "sql": "select `decimallatitude`/10 `lat`, `decimallongitude`/10 `lon`, count(`species`) `count` from `occurrence` GROUP BY `decimallatitude`/10, `decimallongitude`/10",
    "issues": [],
    "explain": [
        "STAGE DEPENDENCIES:",
        "  Stage-1 is a root stage",
        "  Stage-0 depends on stages: Stage-1",
        "",
        "STAGE PLANS:",
        "  Stage: Stage-1",
        "    Map Reduce",
        "      Map Operator Tree:",
        "          TableScan",
        "            alias: occurrence_hdfs",
        "            Statistics: Num rows: 915 Data size: 7309824 Basic stats: COMPLETE Column stats: NONE",
        "            Select Operator",
        "              expressions: decimallatitude (type: double), decimallongitude (type: double), species (type: string)",
        "              outputColumnNames: decimallatitude, decimallongitude, species",
        "              Statistics: Num rows: 915 Data size: 7309824 Basic stats: COMPLETE Column stats: NONE",
        "              Group By Operator",
        "                aggregations: count(species)",
        "                keys: (decimallatitude / 10) (type: double), (decimallongitude / 10) (type: double)",
        "                mode: hash",
        "                outputColumnNames: _col0, _col1, _col2",
        "                Statistics: Num rows: 915 Data size: 7309824 Basic stats: COMPLETE Column stats: NONE",
        "                Reduce Output Operator",
        "                  key expressions: _col0 (type: double), _col1 (type: double)",
        "                  sort order: ++",
        "                  Map-reduce partition columns: _col0 (type: double), _col1 (type: double)",
        "                  Statistics: Num rows: 915 Data size: 7309824 Basic stats: COMPLETE Column stats: NONE",
        "                  value expressions: _col2 (type: bigint)",
        "      Execution mode: vectorized",
        "      Reduce Operator Tree:",
        "        Group By Operator",
        "          aggregations: count(VALUE._col0)",
        "          keys: KEY._col0 (type: double), KEY._col1 (type: double)",
        "          mode: mergepartial",
        "          outputColumnNames: _col0, _col1, _col2",
        "          Statistics: Num rows: 457 Data size: 3650917 Basic stats: COMPLETE Column stats: NONE",
        "          File Output Operator",
        "            compressed: false",
        "            Statistics: Num rows: 457 Data size: 3650917 Basic stats: COMPLETE Column stats: NONE",
        "            table:",
        "                input format: org.apache.hadoop.mapred.TextInputFormat",
        "                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat",
        "                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe",
        "",
        "  Stage: Stage-0",
        "    Fetch Operator",
        "      limit: -1",
        "      Processor Tree:",
        "        ListSink",
        ""
    ],
    "isOk": true
} 
```

#### SQL Download 

Authorization needed

##### Sample Request

```
POST /v1/occurrence/download/request/sql HTTP/1.1
Host: api.gbif.org
Content-Type: application/json
Authorization: Basic cnBhdGhhazptZXJwYXRoYWs=
cache-control: no-cache
{
  "creator": "user",
  "notification_address": [
    "user@lab.edu"
  ],
  "send_notification": "true",
  "format": "SQL",
  "sql": "select `decimallatitude`/10 `lat`, `decimallongitude`/10 `lon`, count(`species`) `count` from `occurrence` GROUP BY `decimallatitude`/10, `decimallongitude`/10"
}
```

##### Sample Response

0001041-180611120914121

### Rules for SQL query

SQL query supported by GBIF API need to follow some rules, they are :
1. Sql query supported format: <br/>
   SELECT `<field1>`,`<field2>`,`<field3>`,`<field4>` FROM occurrence WHERE `<condition1>` AND `<condition2>` OR `<condition3>` …  GROUP BY …
2. All the identifier in query should be quoted by ` (back quotes). It is not hard requirement but there are conflicts with SQL keywords and DWCA fields. So it is important that these fields are back quoted to be parsed correctly. The reserved keywords for SQL are mentioned [here](#sql-keywords).  
3. ORDER BY, DML queries, SET queries (UNION, INTERSECT), Subqueries (AS), JOINS not allowed.
4. Table name should always be “occurrence”.	
5. ‘*’ can’t be used, provide fields for selection explicitly.
6. HAVING clause not supported.

### SQL Functions supported

[SQL Download API supports all built in functions of hive 1.1. Please refer](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-Built-inFunctions)

### Citation and Licenses for Downloads

License for the query which produces new data from old ones, i.e those which has functions and aggregations from entire datasets in gbif are licensed as CC by 4.0 and cites gbif. All other queries has restrictive download license based on the datasets used, and cites them as usual.

## Getting started

Prerequisite :
1. gbif-account
2. [curl](https://curl.haxx.se/)
3. Web browser 

**Step 1.** Describe all gbif fields to know the fields to query <br/>

```
curl -X GET \
  https://api.gbif.org/v1/occurrence/download/request/sql/describe \
  -H 'cache-control: no-cache'
```

**Step 2.** Select the required fields from the Step 1 and form a desired sql query <br/>
For example, we want to know the count of species available in 10*10 square grid of the world map.

```
select `decimallatitude`/10`lat`, `decimallongitude`/10 `lon`,  count(`species`) `count` from `occurrence` group by `decimallatitude`/10, `decimallongitude`/10 
```
Validate the query with SQL validation service

```
curl -X GET \
  'http://api.gbif.org/v1/occurrence/download/request/sql/validate?sql=select%20`decimallatitude`/10`lat`,%20`decimallongitude`/10%20`lon`,%20%20count%28`species`%29%20`count`%20from%20`occurrence`%20group%20by%20`decimallatitude`/10,%20`decimallongitude`/10' \
  -H 'Content-Type: application/json' \
  -H 'cache-control: no-cache'
```

You get a json response, and check for -> "issues": []. If you have issues they will be highlighted and described here.

**Step 3.** When the query is finalised, Create a download request using following steps


```
curl -X POST   http://api.gbif.org/v1/occurrence/download/request/sql   --user <username>:<password>   -H 'Content-Type: application/json'   -H 'cache-control: no-cache'   -d '{
  "creator": "<user>",
  "notification_address": [
    "user@lab.edu"
  ],
  "send_notification": "true",
  "format": "SQL",
  "sql": "select `decimallatitude`/10 `lat`, `decimallongitude`/10 `lon`,  count(`species`) `count` from `occurrence` group by `decimallatitude`/10, `decimallongitude`/10"
}
 '
```

you get download key which can be tracked online for downloads or turn on notification by making send_notification: true and adding your email id in notification_address field of above curl statement.

For example to track the download for downloadkey= 0000015-181121175518854, open the web browser in your computer and navigate to <br/>
[https://www.gbif.org/occurrence/download/0000015-181121175518854](https://www.gbif-dev.org/occurrence/download/0000015-181121175518854)

## Future Works

1. Removing back quotes(`) from identifiers.
2. Supporting HAVING clause

## Open Questions

## Conclusion
SQL Download API help creating, transforming and downloading GBIF occurrence data as SQL queries. 

##### SQL Keywords
```
ABSOLUTE,ACTION,ADD,ALL,ALLOCATE,ALTER,AND,ANY,ARE,AS,ASC,ASSERTION,AT,AUTHORIZATION,AVG,BEGIN,BETWEEN,BIT,BIT_LENGTH,BOTH,BY,CASCADE,CASCADED,CASE,CAST,CATALOG,CHAR,CHARACTER,
CHARACTER_LENGTH,CHAR_LENGTH,CHECK,CLOSE,COALESCE,COLLATE,COLLATION,COLUMN,COMMIT,CONNECT,CONNECTION,CONSTRAINT,CONSTRAINTS,CONTINUE,CONVERT,CORRESPONDING,COUNT,CREATE,CROSS,
CURRENT,CURRENT_DATE,CURRENT_TIME,CURRENT_TIMESTAMP,CURRENT_USER,CURSOR,DATE,DAY,DEALLOCATE,DEC,DECIMAL,DECLARE,DEFAULT,DEFERRABLE,DEFERRED,DELETE,DESC,DESCRIBE,DESCRIPTOR,
DIAGNOSTICS,DISCONNECT,DISTINCT,DOMAIN,DOUBLE,DROP,ELSE,END,ENDEXEC,ESCAPE,EXCEPT,EXCEPTION,EXEC,EXECUTE,EXISTS,EXTERNAL,EXTRACT,FALSE,FETCH,FIRST,FLOAT,FOR,FOREIGN,FOUND,
FROM,FULL,GET,GLOBAL,GO,GOTO,GRANT,GROUP,HAVING,HOUR,IDENTITY,IMMEDIATE,IN,INDICATOR,INITIALLY,INNER,INADD,INSENSITIVE,INSERT,INT,INTEGER,INTERSECT,INTERVAL,INTO,IS,ISOLATION,
JOIN,KEY,LANGUAGE,LAST,LEADING,LEFT,LEVEL,LIKE,LOCAL,LOWER,MATCH,MAX,MIN,MINUTE,MODULE,MONTH,NAMES,NATIONAL,NATURAL,NCHAR,NEXT,NO,NOT,NULL,NULLIF,NUMERIC,OCTET_LENGTH,OF,
ON,ONLY,OPEN,OPTION,OR,ORDER,OUTER,OUTADD,OVERLAPS,PAD,PARTIAL,POSITION,PRECISION,PREPARE,PRESERVE,PRIMARY,PRIOR,PRIVILEGES,PROCEDURE,PUBLIC,READ,REAL,REFERENCES,RELATIVE,
RESTRICT,REVOKE,RIGHT,ROLLBACK,ROWS,SCHEMA,SCROLL,SECOND,SECTION,SELECT,SESSION,SESSION_USER,SET,SIZE,SMALLINT,SOME,SPACE,SQL,SQLCODE,SQLERROR,SQLSTATE,SUBSTRING,SUM,
SYSTEM_USER,TABLE,TEMPORARY,THEN,TIME,TIMESTAMP,TIMEZONE_HOUR,TIMEZONE_MINUTE,TO,TRAILING,TRANSACTION,TRANSLATE,TRANSLATION,TRIM,TRUE,UNION,UNIQUE,UNKNOWN,UPDATE,UPPER,
USAGE,USER,USING,VALUE,VALUES,VARCHAR,VARYING,VIEW,WHEN,WHENEVER,WHERE,WITH,WORK,WRITE,YEAR,ZONE
```
